{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3029e100-8294-4f00-95df-09eb2c1df926",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is one part of the Data Investigation Process that can include data cleaning, wrangling, and visualization. The \"Data Moves\" framework:\n",
    "\n",
    "- Provides a structured set of categories (i.e., data moves) to describe and analyze how students engage with data\n",
    "\n",
    "- Supports instructional design and assessment by offering a lens through which educators can identify, understand, and demonstrate data practices\n",
    "\n",
    "Before exploring data, it is important to select datasets that are appropriate for students based on grade-level, subject area relevance, size, and number of freatures (i.e., variables). This notebook covers basic considerations that should be made before selecting datasets suitable for use in exploratory data analysis within an introductory data science course. It also provides examples of the core data moves along with explanations of output generated by each the move (e.g, a value, table, visualization, etc.).\n",
    "\n",
    "## Selecting a Dataset\n",
    "\n",
    "### Tidy Data\n",
    "\n",
    "The 2014 paper *Tidy Data* presents a structured framework for organizing datasets to support efficient analysis. In a tidy dataset, each variable forms a column, each observation forms a row, and each type of observational unit is stored in a separate table. It also outlines strategies for transforming messy data into tidy form, demonstrating how this approach simplifies and strengthens data analysis practices.\n",
    "\n",
    "Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10\n",
    "\n",
    "### Tame Data\n",
    "\n",
    "The 2018 paper The fivethirtyeight R Package introduces the concept of tame data, which refers to datasets that are clean, well-labeled, and easy to use in teaching. Tame data minimizes the need for wrangling so students can focus on analysis. The paper highlights the importance of using structured and accessible data in introductory statistics and data science courses.\n",
    "\n",
    "Kim, A. Y., Ismay, C., & Chunn, J. (2018). The fivethirtyeight R Package: “Tame Data” Principles for Introductory Statistics and Data Science Courses. Technology Innovations in Statistics Education, 11(1). https://doi.org/10.5070/T5111035892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de5ad7-ef7e-4cd1-abc2-5b1745f3fb70",
   "metadata": {},
   "source": [
    "## Investigating Data Like a Data Scientist\n",
    "\n",
    "Investigating data like a data scientist involves an iterative process of making sense of information. This process includes six key phases: \n",
    "\n",
    "- Framing the problem\n",
    "- Exploring and visualizing data\n",
    "- Modeling\n",
    "- Evaluating results\n",
    "- Crafting a narrative\n",
    "- Communicating findings\n",
    "\n",
    "These phases reflect authentic data science practice and provide a structure that support more meaningful engagement with data in educational settings.\n",
    "\n",
    "Rather than following a fixed procedure, this framework emphasizes the importance of habits of mind such as critical thinking, refining questions, and considering the audience. It highlights that data science relies not only on technical skills but also on decision-making, interpretation, and storytelling. When students are guided through these phases, they develop the analytical reasoning needed to navigate data and communicate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f700d5-9b19-402f-a43b-518b9eac5bce",
   "metadata": {},
   "source": [
    "## Data Investigation Process Framework\n",
    "\n",
    "\n",
    "### Frame Problem\n",
    "\n",
    "- Consider real-world phenomena and broader issues related to the problem\n",
    "- Pose investigative question(s)\n",
    "- Anticipate potential data and strategies\n",
    "\n",
    "### Consider & Gather Data\n",
    "\n",
    "- Understand possible attributes, measurements, and data collection methods needed for the problem\n",
    "- Evaluate and use appropriate design and techniques to collect or source data\n",
    "- Consider sample size, access, storage, and trustworthiness of data\n",
    "\n",
    "### Process Data\n",
    "\n",
    "- Organize, structure, clean, and transform data in efficient and useful ways\n",
    "- Consider additional data cases or attributes\n",
    "\n",
    "### Explore & Visualize Data\n",
    "\n",
    "- Construct meaningful visualizations, static or dynamic\n",
    "- Compute meaningful statistical measures\n",
    "- Explore and analyze data for potential relationships or patterns that address the problem\n",
    "\n",
    "### Consider Models\n",
    "\n",
    "- Analyze and identify models that address the problem\n",
    "- Consider assumptions and context of the models\n",
    "- Recognize possible limitations\n",
    "\n",
    "### Communicate & Propose Action\n",
    "\n",
    "- Craft a data story to convey insight to stakeholder audiences\n",
    "- Justify claims with evidence from data and propose possible action\n",
    "- Address uncertainty, constraints, and potential bias in the analysis\n",
    "\n",
    "Lee, H. S., Wilkerson, M. H., & Zuckerman, S. J. (2022). Investigating data like a data scientist: A framework for elementary, middle, and high school teachers. *Statistics Education Research Journal, 21*(2). [https://doi.org/10.52041/serj.v21i2.41](https://doi.org/10.52041/serj.v21i2.41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f8e39-2cac-4cbe-a3de-a1bab5569fe1",
   "metadata": {},
   "source": [
    "# Data Moves\n",
    "\n",
    "Data moves are strategic actions taken during data analysis to reshape and prepare datasets for interpretation. These include filtering, grouping, summarizing, calculating, merging or joining data, and creating hierarchical structures. Each move alters the structure, content, or values of a dataset, influencing what patterns become visible and what questions can be explored. By understanding these moves, learners gain insight into how data analysis is an active, decision-driven process rather than a passive application of procedures.\n",
    "\n",
    "Erickson, T., Tinker, R., & Yasuda, M. (2019). *Data moves*. UC Berkeley: The Concord Consortium. eScholarship, University of California. https://escholarship.org/uc/item/0mg8m7g6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d552caf-707d-402b-b270-b5180299c83b",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "Grouping is used to set up a comparison among different subgroups of a dataset. Just as filtering restricts analysis to a single subset, grouping divides a dataset into multiple subsets. This division is guided by the available value(s) of some attribute or attributes so that, among the cases within each resulting group, the values of these \"grouping\" attributes are the same.\n",
    "\n",
    "**Note:** Grouping and summarizing are often used together to simplify complex datasets by reducing them to fewer data points that highlight overall patterns. However, this simplification can result in a loss of detail, such as variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753976c-790e-4597-85a4-7ed22449e3e3",
   "metadata": {},
   "source": [
    "# Data Dive\n",
    "\n",
    "A data dive is a focused exploratory analysis where students work closely with a dataset to uncover patterns, trends, and relationships by applying key data moves. For example, using a dataset about school lunch nutrition, students might begin by filtering to isolate meals served in a specific year or location. They could group the data by food category such as fruits, grains, or proteins to explore how nutritional content differs across types. Through summarizing, they might calculate the average number of calories or the typical sodium content for each group. Calculating might involve creating new variables, such as calories per gram or the percentage of a recommended daily intake. If additional data sources are provided, students could join datasets, such as connecting lunch menus with student demographic information, to add context and depth to their findings. These data moves help students make sense of multivariable datasets and support evidence-based insights.\n",
    "\n",
    "## Analysis with Data Moves in Python\n",
    "\n",
    "In this section, we present example use cases that demonstrate data moves using the Python programming language. While Python includes built-in tools and data structures for general data handling, it does not include a built-in data structure specifically designed for working with tidy data as defined by the _Tidy Data_ paper. To support the tidy data format and organize the analysis around data moves such as filtering, grouping, and summarizing, we will use the Pandas library for data wrangling, Numpy for scientific computing, and the Matplotlib library for creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba0a40-3b44-4635-9616-fbf8adfca33a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49403-b64c-445b-8e65-26afa6ef46bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8741ee1-ddbd-4df1-bb29-f2bbd529e22a",
   "metadata": {},
   "source": [
    "### Updated Starwars Dataset\n",
    "\n",
    "Fabricio Narcizo’s blog post, Introduction to Data Analysis using the Star Wars Dataset, presents an expanded version of the original R dplyr Star Wars dataset, growing it from 14 to 25 variables. By cross-referencing Wookieepedia, he corrected and enriched the character data with new fields like birth/death details, pronouns, occupations, and abilities, resulting in a more accurate and comprehensive dataset for analysis.\n",
    "\n",
    "#### Updated Starwars Datasheet\n",
    "\n",
    "[Updated Starwars Datasheet](https://docs.google.com/document/d/1Gr6W0xo1pxW-TZH2GKawIASqZ7JfURmzQO1Eg2JGsC8/edit?usp=sharing)\n",
    "\n",
    "Narcizo, F. B. (2023, December 30). Introduction to Data Analysis using the Star Wars Dataset. Retrieved from https://www.fabricionarcizo.com/post/starwars/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3076ce3-0bb2-4b49-a50d-6552bd38faf9",
   "metadata": {},
   "source": [
    "**Example 1.** Load the dataset into a pandas `DataFrame` called `starwars`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34680e91-0c05-4f70-a02e-68e20c916ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars = pd.read_csv(\"data/updated_starwars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc88d26-5b6d-46e5-a296-f8ce1c288d67",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664784a5",
   "metadata": {},
   "source": [
    "`group_species` is a user-defined function that classifies a species value as either `\"Human\"`, `\"Droid\"`, or `\"Other\"`. It takes a single input, `s`, which must be a string of `None`. If the input is `\"Human\"` or `\"Droid\"`, the function returns that same value. If the input is anything other species name or missing values, it returns `\"Other\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ff19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_species(s):\n",
    "    \"\"\"\n",
    "    Classifies a species value as 'Human', 'Droid', or 'Other'.\n",
    "    \n",
    "    Examples:\n",
    "    \n",
    "    group_species(\"Human\")  returns \"Human\"\n",
    "    group_species(\"Rodian\") returns \"Other\"\n",
    "    group_species(\"Droid\")  returns \"Droid\"\n",
    "\n",
    "    Parameters:\n",
    "    s: A single species value from the dataset.\n",
    "\n",
    "    Returns:\n",
    "    str: Returns 'Human' or 'Droid' if the input matches those values. \n",
    "         Otherwise returns 'Other'.\n",
    "         \n",
    "    Precondition: s is a string or None\n",
    "    \"\"\"\n",
    "    if s in [\"Human\", \"Droid\"]:\n",
    "        return s\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .apply() runs the group_species function on each value in the 'species' column\n",
    "# It goes through the column one row at a time\n",
    "# This returns a Series of values of 'Human', 'Droid', or 'Other'\n",
    "starwars[\"species_grps\"] = starwars[\"species\"].apply(group_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b3126-a7f3-47aa-bbcb-1676451bfe3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .groupby() method is used to group the DataFrame by the \n",
    "# values in 'species_grps' column\n",
    "# It creates a GroupBy object that allows you to perform \n",
    "# operations separately for each group\n",
    "starwars.groupby(\"species_grps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33642eeb-55e8-4342-8949-6c52fa0d983f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses the .groupby() method to group the DataFrame by the 'species_grps' column\n",
    "# Stores the resulting GroupBy object in the variable 'grps'\n",
    "grps = starwars.groupby(\"species_grps\")\n",
    "\n",
    "# Accesses the dictionary of group labels (keys) from the GroupBy object\n",
    "# This returns a view object with the unique values \n",
    "# in 'species_grps' that were used to form the groups\n",
    "grps.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586578fc-aa08-4385-bf86-cc4c1d1f5043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accesses the .groups attribute of the GroupBy object\n",
    "# This returns a dictionary where the keys are group labels (e.g., 'Human', 'Droid', 'Other')\n",
    "# and the values are lists of row indices from the DataFrame that belong to each group\n",
    "grps.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d731e7-d77b-47bb-b87b-037576bcb94d",
   "metadata": {},
   "source": [
    "**Example 2.** Use the `grps` `GroupBy` object to calculate the average mass for each species group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55064a1-09b2-445c-ba8f-dc45e371f576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'mass' column from the GroupBy object 'grps'\n",
    "# Uses the .mean() method to calculate the average mass for each group in 'species_grps'\n",
    "# Returns a Series showing the mean mass for Humans, Droids, and Other species\n",
    "grps[\"mass\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0125e1-3aa9-45e3-8a1f-c2a81627d459",
   "metadata": {},
   "source": [
    "**Output Observations:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968bf63-da95-4bd2-befc-b2303427dc28",
   "metadata": {},
   "source": [
    "**Example 3.** Use the `grps` `GroupBy` object to count how many times each homeworld appears within each species group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95693627-71f2-4311-b833-a01eeb08333c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'homeworld' column from the GroupBy object 'grps'\n",
    "# Applies .value_counts() to count how many times each homeworld appears within each species group\n",
    "# Returns a Series with counts of homeworlds for 'Human', 'Droid', and 'Other' groups\n",
    "grps[\"homeworld\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada248d-0682-41e0-aacf-e8d183020a4e",
   "metadata": {},
   "source": [
    "**Example 4.** Create a box plot to compare the distribution of character heights across the three species groups: `\"Human\"`, `\"Droid\"`, and `\"Other\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a7936-80f1-4bbd-ba0e-911010c59562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a box plot of the 'height' column grouped by 'species_grps'\n",
    "# This shows the median, quartiles, and possible outliers for each group\n",
    "starwars.boxplot(column=\"height\", by=\"species_grps\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b80612-2f82-4633-9d37-03f20d166561",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
