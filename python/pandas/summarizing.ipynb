{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3029e100-8294-4f00-95df-09eb2c1df926",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is one part of the Data Investigation Process that can include data cleaning, wrangling, and visualization. The \"Data Moves\" framework:\n",
    "\n",
    "- Provides a structured set of categories (i.e., data moves) to describe and analyze how students engage with data\n",
    "\n",
    "- Supports instructional design and assessment by offering a lens through which educators can identify, understand, and demonstrate data practices\n",
    "\n",
    "Before exploring data, it is important to select datasets that are appropriate for students based on grade-level, subject area relevance, size, and number of freatures (i.e., variables). This notebook covers basic considerations that should be made before selecting datasets suitable for use in exploratory data analysis within an introductory data science course. It also provides examples of the core data moves along with explanations of output generated by each the move (e.g, a value, table, visualization, etc.).\n",
    "\n",
    "## Selecting a Dataset\n",
    "\n",
    "### Tidy Data\n",
    "\n",
    "The 2014 paper *Tidy Data* presents a structured framework for organizing datasets to support efficient analysis. In a tidy dataset, each variable forms a column, each observation forms a row, and each type of observational unit is stored in a separate table. It also outlines strategies for transforming messy data into tidy form, demonstrating how this approach simplifies and strengthens data analysis practices.\n",
    "\n",
    "Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10\n",
    "\n",
    "### Tame Data\n",
    "\n",
    "The 2018 paper The fivethirtyeight R Package introduces the concept of tame data, which refers to datasets that are clean, well-labeled, and easy to use in teaching. Tame data minimizes the need for wrangling so students can focus on analysis. The paper highlights the importance of using structured and accessible data in introductory statistics and data science courses.\n",
    "\n",
    "Kim, A. Y., Ismay, C., & Chunn, J. (2018). The fivethirtyeight R Package: “Tame Data” Principles for Introductory Statistics and Data Science Courses. Technology Innovations in Statistics Education, 11(1). https://doi.org/10.5070/T5111035892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de5ad7-ef7e-4cd1-abc2-5b1745f3fb70",
   "metadata": {},
   "source": [
    "## Investigating Data Like a Data Scientist\n",
    "\n",
    "Investigating data like a data scientist involves an iterative process of making sense of information. This process includes six key phases: \n",
    "\n",
    "- Framing the problem\n",
    "- Exploring and visualizing data\n",
    "- Modeling\n",
    "- Evaluating results\n",
    "- Crafting a narrative\n",
    "- Communicating findings\n",
    "\n",
    "These phases reflect authentic data science practice and provide a structure that support more meaningful engagement with data in educational settings.\n",
    "\n",
    "Rather than following a fixed procedure, this framework emphasizes the importance of habits of mind such as critical thinking, refining questions, and considering the audience. It highlights that data science relies not only on technical skills but also on decision-making, interpretation, and storytelling. When students are guided through these phases, they develop the analytical reasoning needed to navigate data and communicate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f700d5-9b19-402f-a43b-518b9eac5bce",
   "metadata": {},
   "source": [
    "## Data Investigation Process Framework\n",
    "\n",
    "\n",
    "### Frame Problem\n",
    "\n",
    "- Consider real-world phenomena and broader issues related to the problem\n",
    "- Pose investigative question(s)\n",
    "- Anticipate potential data and strategies\n",
    "\n",
    "### Consider & Gather Data\n",
    "\n",
    "- Understand possible attributes, measurements, and data collection methods needed for the problem\n",
    "- Evaluate and use appropriate design and techniques to collect or source data\n",
    "- Consider sample size, access, storage, and trustworthiness of data\n",
    "\n",
    "### Process Data\n",
    "\n",
    "- Organize, structure, clean, and transform data in efficient and useful ways\n",
    "- Consider additional data cases or attributes\n",
    "\n",
    "### Explore & Visualize Data\n",
    "\n",
    "- Construct meaningful visualizations, static or dynamic\n",
    "- Compute meaningful statistical measures\n",
    "- Explore and analyze data for potential relationships or patterns that address the problem\n",
    "\n",
    "### Consider Models\n",
    "\n",
    "- Analyze and identify models that address the problem\n",
    "- Consider assumptions and context of the models\n",
    "- Recognize possible limitations\n",
    "\n",
    "### Communicate & Propose Action\n",
    "\n",
    "- Craft a data story to convey insight to stakeholder audiences\n",
    "- Justify claims with evidence from data and propose possible action\n",
    "- Address uncertainty, constraints, and potential bias in the analysis\n",
    "\n",
    "Lee, H. S., Wilkerson, M. H., & Zuckerman, S. J. (2022). Investigating data like a data scientist: A framework for elementary, middle, and high school teachers. *Statistics Education Research Journal, 21*(2). [https://doi.org/10.52041/serj.v21i2.41](https://doi.org/10.52041/serj.v21i2.41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f8e39-2cac-4cbe-a3de-a1bab5569fe1",
   "metadata": {},
   "source": [
    "# Data Moves\n",
    "\n",
    "Data moves are strategic actions taken during data analysis to reshape and prepare datasets for interpretation. These include filtering, grouping, summarizing, calculating, merging or joining data, and creating hierarchical structures. Each move alters the structure, content, or values of a dataset, influencing what patterns become visible and what questions can be explored. By understanding these moves, learners gain insight into how data analysis is an active, decision-driven process rather than a passive application of procedures.\n",
    "\n",
    "Erickson, T., Tinker, R., & Yasuda, M. (2019). *Data moves*. UC Berkeley: The Concord Consortium. eScholarship, University of California. https://escholarship.org/uc/item/0mg8m7g6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d9d92-1123-4548-81d8-fda62ad5a6e3",
   "metadata": {},
   "source": [
    "## Summarizing\n",
    "\n",
    "Summarizing is the process of producing and recording a summary or aggregate value, i.e., a statistic. \n",
    "\n",
    "- The mean is a common summary function, but it is not the only option.\n",
    "- Summary measures are not limited to numerical or “typical” values.\n",
    "- Some summaries are non-numerical, i.e., identifying the most common category such as the most frequently mentioned pet type (\"dog\") in a survey.\n",
    "- The purpose of summarizing is not always to focus on the measure itself or to compare across groups; an aggregate value can also serve as data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753976c-790e-4597-85a4-7ed22449e3e3",
   "metadata": {},
   "source": [
    "# Data Dive\n",
    "\n",
    "A data dive is a focused exploratory analysis where students work closely with a dataset to uncover patterns, trends, and relationships by applying key data moves. For example, using a dataset about school lunch nutrition, students might begin by filtering to isolate meals served in a specific year or location. They could group the data by food category such as fruits, grains, or proteins to explore how nutritional content differs across types. Through summarizing, they might calculate the average number of calories or the typical sodium content for each group. Calculating might involve creating new variables, such as calories per gram or the percentage of a recommended daily intake. If additional data sources are provided, students could join datasets, such as connecting lunch menus with student demographic information, to add context and depth to their findings. These data moves help students make sense of multivariable datasets and support evidence-based insights.\n",
    "\n",
    "## Analysis with Data Moves in Python\n",
    "\n",
    "In this section, we present example use cases that demonstrate data moves using the Python programming language. While Python includes built-in tools and data structures for general data handling, it does not include a built-in data structure specifically designed for working with tidy data as defined by the _Tidy Data_ paper. To support the tidy data format and organize the analysis around data moves such as filtering, grouping, and summarizing, we will use the Pandas library for data wrangling, Numpy for scientific computing, and the Matplotlib library for creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba0a40-3b44-4635-9616-fbf8adfca33a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49403-b64c-445b-8e65-26afa6ef46bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8741ee1-ddbd-4df1-bb29-f2bbd529e22a",
   "metadata": {},
   "source": [
    "### Updated Starwars Dataset\n",
    "\n",
    "Fabricio Narcizo’s blog post, Introduction to Data Analysis using the Star Wars Dataset, presents an expanded version of the original R dplyr Star Wars dataset, growing it from 14 to 25 variables. By cross-referencing Wookieepedia, he corrected and enriched the character data with new fields like birth/death details, pronouns, occupations, and abilities, resulting in a more accurate and comprehensive dataset for analysis.\n",
    "\n",
    "#### Updated Starwars Datasheet\n",
    "\n",
    "[Updated Starwars Datasheet](https://docs.google.com/document/d/1Gr6W0xo1pxW-TZH2GKawIASqZ7JfURmzQO1Eg2JGsC8/edit?usp=sharing)\n",
    "\n",
    "Narcizo, F. B. (2023, December 30). Introduction to Data Analysis using the Star Wars Dataset. Retrieved from https://www.fabricionarcizo.com/post/starwars/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3076ce3-0bb2-4b49-a50d-6552bd38faf9",
   "metadata": {},
   "source": [
    "**Example 1.** Load the dataset into a pandas `DataFrame` called `starwars`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34680e91-0c05-4f70-a02e-68e20c916ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars = pd.read_csv(\"data/updated_starwars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951ec9e-f6d6-4b35-b1ad-6d1fba3a884d",
   "metadata": {},
   "source": [
    "### Summarzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c3d75-288d-4621-925d-88c0018606b8",
   "metadata": {},
   "source": [
    "**Example 2.** Use the `.info()` method to display a summary of the `starwars` dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0f579-6a59-4108-b8b8-8a4ae4ba8a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .info() is a method that gives a quick summary of the DataFrame\n",
    "# It shows the number of rows and columns\n",
    "# It lists the column names and their data types\n",
    "# It tells how many non-missing values are in each column\n",
    "starwars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb1c38-58bc-474c-b586-5be7f3342777",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3583f-bac8-4b77-ab13-2eb9a34f0547",
   "metadata": {},
   "source": [
    "**Example 3.** Select and display the `mass` column from the `starwars` dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90792a5-680c-447a-a7c3-34388a141dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'mass' column from the starwars DataFrame\n",
    "# Returns a Series of character masses\n",
    "# The index on the left corresponds to the row number (i.e., each character)\n",
    "# NaN means that the mass value is missing for that character\n",
    "starwars[\"mass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb3f85-ce94-4a98-a238-8035450a77f8",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e646c-5a85-4eed-8275-5e653b952d95",
   "metadata": {},
   "source": [
    "**Example 4.** Use the `.describe()` method to generate summary statistics for the `mass` column in the `starwars` dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942df34-2379-4fcb-bfbd-35b673cb8e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates summary statistics for the 'mass' column\n",
    "# count – number of non-missing values\n",
    "# mean – average mass\n",
    "# std – standard deviation (shows spread)\n",
    "# min – smallest mass\n",
    "# 25%, 50%, 75% – quartiles (values that split the data into four parts)\n",
    "# max – largest mass\n",
    "starwars[\"mass\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ff4a-50d6-4155-a45c-6a5f0dd579e0",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef11a4f-e46e-4e39-8869-154e2d99d6f1",
   "metadata": {},
   "source": [
    "**Example 5.** Create a histogram of the `mass` column to visualize the distribution of character masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d6f69-d204-4b27-b2a7-ca07ec9cd304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"mass\"] uses bracket notation to select a single column from the DataFrame\n",
    "# The result is a pandas Series containing just the 'mass' values\n",
    "# .hist() creates a histogram to show the frequency of different mass ranges\n",
    "starwars[\"mass\"].hist()\n",
    "\n",
    "# Turns off the background grid in the plot for a cleaner visual\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a0c8e-6ca2-4501-89d8-5cf502ce4602",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3548efc-0c0c-4ddc-8055-db30dd53b42a",
   "metadata": {},
   "source": [
    "**Example 6.** Count how many times each species appears in the `species` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc47f1-d840-45c3-9340-aa6d375bc739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"species\"] uses bracket notation to select the 'species' column from the DataFrame\n",
    "# This returns a pandas Series containing all species values\n",
    "# .value_counts() counts how many times each unique value appears\n",
    "# The result is sorted by count, from most to least common\n",
    "starwars[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee0b64-84d7-4f14-a230-dbf954219b0a",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510ecbd-26cc-4131-ad59-f04af11fa700",
   "metadata": {},
   "source": [
    "**Example 7.** Create a horizontal bar chart to visualize the species counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb530d-97a7-4205-89a4-cf03e7c24120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"species\"] uses bracket notation to select the 'species' column\n",
    "# .value_counts() counts how many times each species appears\n",
    "# The result is saved to a variable called tbl\n",
    "tbl = starwars[\"species\"].value_counts()\n",
    "\n",
    "# Creates a horizontal bar chart of the species counts\n",
    "# kind='barh' specifies a horizontal bar plot\n",
    "tbl.plot(kind = 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a262539-4605-419d-b48d-dabaebbfe165",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f2789-334b-400d-b748-03c08843930c",
   "metadata": {},
   "source": [
    "**Example 8.** Create a horizontal bar chart to visualize the species counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b719-f6dc-425b-a67c-19a4e930672f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count how many times each species appears\n",
    "tbl = starwars[\"species\"].value_counts()\n",
    "\n",
    "# Combine all species from index 2 onward (everything except the top 2) \n",
    "# into a new Series labeled \"Other\"\n",
    "other = pd.Series([tbl[2:].sum()], index=[\"Other\"])\n",
    "\n",
    "# Concatenate the top 2 species with the \"Other\" group\n",
    "# Then sort the result so the bars appear in order from \n",
    "# smallest to largest\n",
    "pd.concat([tbl.iloc[0:2], other]).sort_values(ascending=True).plot(kind = 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e12e28-3f1c-4b9d-8465-4f0a1632cf5a",
   "metadata": {},
   "source": [
    "**Output Observations:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a75412-7e06-4675-9e0c-2afc3f4943a8",
   "metadata": {},
   "source": [
    "**Example 9.** Count how many times each eye color appears in the `eye_color` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53404e7-1359-457e-862d-f631cfabbb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'eye_color' column using bracket notation\n",
    "# Returns a Series of eye colors for all characters\n",
    "# .value_counts() counts how many times each unique eye color appears\n",
    "# The result is sorted from most to least frequent\n",
    "starwars[\"eye_color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e2683-713e-4a81-9656-e44866e7374a",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a19052-d496-4e7d-aa27-529f02582af5",
   "metadata": {},
   "source": [
    "**Example 10.** Count how many times each hair color appears in the `hair_color` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06c5ea-1972-4eb0-a5bd-02eb91ab0468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'hair_color' column from the DataFrame using bracket notation\n",
    "# This returns a Series of all hair color values\n",
    "# .value_counts() counts how often each unique value appears\n",
    "# The result is sorted from most to least frequent\n",
    "starwars[\"hair_color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cf0e3-fd42-4ed2-bf97-6cbe5813b2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counts how many times each unique hair color appears\n",
    "# dropna=False includes missing values (NaN) in the count\n",
    "# Without this, missing values would be excluded by default\n",
    "starwars[\"hair_color\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2eb176-027e-49f4-9e5d-09ba34f95a28",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbef3f-58aa-4ac0-9391-354ddc835941",
   "metadata": {},
   "source": [
    "**Example 11.** Create a cross-tabulation table to compare eye color and hair color. Use `pd.crosstab()` to count how many characters have each combination of eye color and hair color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1a37f-853a-465b-b370-14d4a79f0f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a cross-tabulation of eye color (rows) and hair color (columns)\n",
    "# Counts how many characters fall into each combination of eye color and hair color\n",
    "# Stores the result in a new table called tbl\n",
    "tbl = pd.crosstab(starwars[\"eye_color\"], starwars[\"hair_color\"])\n",
    "\n",
    "# Display the resulting table\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c48a8-5ada-47a8-9d08-9dbc9d83801e",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
