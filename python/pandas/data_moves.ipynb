{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3029e100-8294-4f00-95df-09eb2c1df926",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is one part of the Data Investigation Process that can include data cleaning, wrangling, and visualization. The \"Data Moves\" framework:\n",
    "\n",
    "- Provides a structured set of categories (i.e., data moves) to describe and analyze how students engage with data\n",
    "\n",
    "- Supports instructional design and assessment by offering a lens through which educators can identify, understand, and demonstrate data practices\n",
    "\n",
    "Before exploring data, it is important to select datasets that are appropriate for students based on grade-level, subject area relevance, size, and number of freatures (i.e., variables). This notebook covers basic considerations that should be made before selecting datasets suitable for use in exploratory data analysis within an introductory data science course. It also provides examples of the core data moves along with explanations of output generated by each the move (e.g, a value, table, visualization, etc.).\n",
    "\n",
    "## Selecting a Dataset\n",
    "\n",
    "### Tidy Data\n",
    "\n",
    "The 2014 paper *Tidy Data* presents a structured framework for organizing datasets to support efficient analysis. In a tidy dataset, each variable forms a column, each observation forms a row, and each type of observational unit is stored in a separate table. It also outlines strategies for transforming messy data into tidy form, demonstrating how this approach simplifies and strengthens data analysis practices.\n",
    "\n",
    "Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10\n",
    "\n",
    "### Tame Data\n",
    "\n",
    "The 2018 paper The fivethirtyeight R Package introduces the concept of tame data, which refers to datasets that are clean, well-labeled, and easy to use in teaching. Tame data minimizes the need for wrangling so students can focus on analysis. The paper highlights the importance of using structured and accessible data in introductory statistics and data science courses.\n",
    "\n",
    "Kim, A. Y., Ismay, C., & Chunn, J. (2018). The fivethirtyeight R Package: “Tame Data” Principles for Introductory Statistics and Data Science Courses. Technology Innovations in Statistics Education, 11(1). https://doi.org/10.5070/T5111035892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de5ad7-ef7e-4cd1-abc2-5b1745f3fb70",
   "metadata": {},
   "source": [
    "## Investigating Data Like a Data Scientist\n",
    "\n",
    "Investigating data like a data scientist involves an iterative process of making sense of information. This process includes six key phases: \n",
    "\n",
    "- Framing the problem\n",
    "- Exploring and visualizing data\n",
    "- Modeling\n",
    "- Evaluating results\n",
    "- Crafting a narrative\n",
    "- Communicating findings\n",
    "\n",
    "These phases reflect authentic data science practice and provide a structure that support more meaningful engagement with data in educational settings.\n",
    "\n",
    "Rather than following a fixed procedure, this framework emphasizes the importance of habits of mind such as critical thinking, refining questions, and considering the audience. It highlights that data science relies not only on technical skills but also on decision-making, interpretation, and storytelling. When students are guided through these phases, they develop the analytical reasoning needed to navigate data and communicate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f700d5-9b19-402f-a43b-518b9eac5bce",
   "metadata": {},
   "source": [
    "## Data Investigation Process Framework\n",
    "\n",
    "\n",
    "### Frame Problem\n",
    "\n",
    "- Consider real-world phenomena and broader issues related to the problem\n",
    "- Pose investigative question(s)\n",
    "- Anticipate potential data and strategies\n",
    "\n",
    "### Consider & Gather Data\n",
    "\n",
    "- Understand possible attributes, measurements, and data collection methods needed for the problem\n",
    "- Evaluate and use appropriate design and techniques to collect or source data\n",
    "- Consider sample size, access, storage, and trustworthiness of data\n",
    "\n",
    "### Process Data\n",
    "\n",
    "- Organize, structure, clean, and transform data in efficient and useful ways\n",
    "- Consider additional data cases or attributes\n",
    "\n",
    "### Explore & Visualize Data\n",
    "\n",
    "- Construct meaningful visualizations, static or dynamic\n",
    "- Compute meaningful statistical measures\n",
    "- Explore and analyze data for potential relationships or patterns that address the problem\n",
    "\n",
    "### Consider Models\n",
    "\n",
    "- Analyze and identify models that address the problem\n",
    "- Consider assumptions and context of the models\n",
    "- Recognize possible limitations\n",
    "\n",
    "### Communicate & Propose Action\n",
    "\n",
    "- Craft a data story to convey insight to stakeholder audiences\n",
    "- Justify claims with evidence from data and propose possible action\n",
    "- Address uncertainty, constraints, and potential bias in the analysis\n",
    "\n",
    "Lee, H. S., Wilkerson, M. H., & Zuckerman, S. J. (2022). Investigating data like a data scientist: A framework for elementary, middle, and high school teachers. *Statistics Education Research Journal, 21*(2). [https://doi.org/10.52041/serj.v21i2.41](https://doi.org/10.52041/serj.v21i2.41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f8e39-2cac-4cbe-a3de-a1bab5569fe1",
   "metadata": {},
   "source": [
    "# Data Moves\n",
    "\n",
    "Data moves are strategic actions taken during data analysis to reshape and prepare datasets for interpretation. These include filtering, grouping, summarizing, calculating, merging or joining data, and creating hierarchical structures. Each move alters the structure, content, or values of a dataset, influencing what patterns become visible and what questions can be explored. By understanding these moves, learners gain insight into how data analysis is an active, decision-driven process rather than a passive application of procedures.\n",
    "\n",
    "Erickson, T., Tinker, R., & Yasuda, M. (2019). *Data moves*. UC Berkeley: The Concord Consortium. eScholarship, University of California. https://escholarship.org/uc/item/0mg8m7g6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d9d92-1123-4548-81d8-fda62ad5a6e3",
   "metadata": {},
   "source": [
    "## Summarizing\n",
    "\n",
    "Summarizing is the process of producing and recording a summary or aggregate value, i.e., a statistic. \n",
    "\n",
    "- The mean is a common summary function, but it is not the only option.\n",
    "- Summary measures are not limited to numerical or “typical” values.\n",
    "- Some summaries are non-numerical, i.e., identifying the most common category such as the most frequently mentioned pet type (\"dog\") in a survey.\n",
    "- The purpose of summarizing is not always to focus on the measure itself or to compare across groups; an aggregate value can also serve as data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc99e7a-e0e5-4db8-8ab4-d3914da8cac6",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Filtering produces a subset of data and serves at least two important purposes.\n",
    "\n",
    "- If a dataset includes extraneous cases, filtering removes the irrelevant ones. This is sometimes called scoping.\n",
    "- Filtering may be used in order to reduce the complexity or quantity of data in order to gain insight. Sometimes this is called slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba03fb8-09a6-4040-a88a-e02827c9b1f1",
   "metadata": {},
   "source": [
    "## Calculating\n",
    "\n",
    "Calculating is the process of create=ing a new attribute, often represented by a new column in a data table. This typically involves calculating the values in this new attribute using a formula.\n",
    "\n",
    "- Many new attributes are calculated using the values from one or more existing attributes. \n",
    "- Summary measures function as new, conceptual attributes as well; the difference is that they appear on group labels rather than individual data cases.\n",
    "\n",
    "In addition to conceptual attributes, calculating can also be used to create\n",
    "convenience attributes. For example, one may wish to create a categorical\n",
    "attribute whose value is “tall” if an individual’s height is greater than the\n",
    "mean height for their age, and “short” otherwise. Convenience attributes are quite common. Other examples include:\n",
    "\n",
    "- Creating a new column that converts heights to inches instead of centimeters.\n",
    "- Using birth dates included in a dataset to compute subjects’ ages.\n",
    "- Recoding an education attribute from several categories (e.g., \"GED,\" \"high-school graduate,\" \"one year of college,\" \"bachelor’s degree,\" etc.) to fewer (perhaps, \"completed high school,\" \"completed college\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d552caf-707d-402b-b270-b5180299c83b",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "Grouping is used to set up a comparison among different subgroups of a dataset. Just as filtering restricts analysis to a single subset, grouping divides a dataset into multiple subsets. This division is guided by the available value(s) of some attribute or attributes so that, among the cases within each resulting group, the values of these \"grouping\" attributes are the same.\n",
    "\n",
    "**Note:** Grouping and summarizing are often used together to simplify complex datasets by reducing them to fewer data points that highlight overall patterns. However, this simplification can result in a loss of detail, such as variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588b1a9-2729-4323-8ca2-7ffa2dd2c412",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "Merging combines multiple datasets into one. The simplest form of merging concatenates datasets about the same phenomenon but from different sources, for example, combining height data from two different classrooms to make a larger dataset. \n",
    "\n",
    "## Joining\n",
    "\n",
    "Joining is a more complex form of merging. It does not add new cases, but\n",
    "rather adds more information (i.e., new attributes) about existing cases from a\n",
    "separate dataset. For example, in a school system, student demographic data might be stored in one table and test scores in another. Using a student ID as a key, the two tables can be joined to combine information for the same students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753976c-790e-4597-85a4-7ed22449e3e3",
   "metadata": {},
   "source": [
    "# Data Dive\n",
    "\n",
    "A data dive is a focused exploratory analysis where students work closely with a dataset to uncover patterns, trends, and relationships by applying key data moves. For example, using a dataset about school lunch nutrition, students might begin by filtering to isolate meals served in a specific year or location. They could group the data by food category such as fruits, grains, or proteins to explore how nutritional content differs across types. Through summarizing, they might calculate the average number of calories or the typical sodium content for each group. Calculating might involve creating new variables, such as calories per gram or the percentage of a recommended daily intake. If additional data sources are provided, students could join datasets, such as connecting lunch menus with student demographic information, to add context and depth to their findings. These data moves help students make sense of multivariable datasets and support evidence-based insights.\n",
    "\n",
    "## Analysis with Data Moves in Python\n",
    "\n",
    "In this section, we present example use cases that demonstrate data moves using the Python programming language. While Python includes built-in tools and data structures for general data handling, it does not include a built-in data structure specifically designed for working with tidy data as defined by the _Tidy Data_ paper. To support the tidy data format and organize the analysis around data moves such as filtering, grouping, and summarizing, we will use the Pandas library for data wrangling, Numpy for scientific computing, and the Matplotlib library for creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba0a40-3b44-4635-9616-fbf8adfca33a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49403-b64c-445b-8e65-26afa6ef46bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8741ee1-ddbd-4df1-bb29-f2bbd529e22a",
   "metadata": {},
   "source": [
    "### Updated Starwars Dataset\n",
    "\n",
    "Fabricio Narcizo’s blog post, Introduction to Data Analysis using the Star Wars Dataset, presents an expanded version of the original R dplyr Star Wars dataset, growing it from 14 to 25 variables. By cross-referencing Wookieepedia, he corrected and enriched the character data with new fields like birth/death details, pronouns, occupations, and abilities, resulting in a more accurate and comprehensive dataset for analysis.\n",
    "\n",
    "#### Updated Starwars Datasheet\n",
    "\n",
    "[Updated Starwars Datasheet](https://docs.google.com/document/d/1Gr6W0xo1pxW-TZH2GKawIASqZ7JfURmzQO1Eg2JGsC8/edit?usp=sharing)\n",
    "\n",
    "Narcizo, F. B. (2023, December 30). Introduction to Data Analysis using the Star Wars Dataset. Retrieved from https://www.fabricionarcizo.com/post/starwars/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3076ce3-0bb2-4b49-a50d-6552bd38faf9",
   "metadata": {},
   "source": [
    "**Example 1.** Load the dataset into a pandas `DataFrame` called `starwars`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34680e91-0c05-4f70-a02e-68e20c916ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars = pd.read_csv(\"data/updated_starwars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951ec9e-f6d6-4b35-b1ad-6d1fba3a884d",
   "metadata": {},
   "source": [
    "### Summarzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fe871-bf0d-42c1-81fa-42d38aa75d69",
   "metadata": {},
   "source": [
    "**Example 2.** Use the `.head()` method to display a subset of the `starwars` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5befb7-8456-4cb5-8294-18ef2f4b755e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .head() is a method that gives the first 5 rows of a DataFrame\n",
    "starwars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e14f6-8a26-458d-b8d0-90a5981e60d9",
   "metadata": {},
   "source": [
    "**Output Observations:** Each row represents a character, with columns for attributes like name, height, mass, hair color, skin color, eye color, birth year, and more. The data includes both numerical and categorical variables, with some missing values (e.g., `NaN` for hair color or birth place). Some fields, like skin color, contain multiple comma-separated values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c3d75-288d-4621-925d-88c0018606b8",
   "metadata": {},
   "source": [
    "**Example 3.** Use the `.info()` method to display a summary of the `starwars` dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0f579-6a59-4108-b8b8-8a4ae4ba8a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .info() is a method that gives a quick summary of the DataFrame\n",
    "# It shows the number of rows and columns\n",
    "# It lists the column names and their data types\n",
    "# It tells how many non-missing values are in each column\n",
    "starwars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb1c38-58bc-474c-b586-5be7f3342777",
   "metadata": {},
   "source": [
    "**Output Observations:** The dataframe contains 87 entries (rows) and 25 variables (columns), each representing a different piece of information about Star Wars characters. Most columns use the `object` data type (often for text), while a few use `float64` for numerical values. Some columns, like `name`, `gender`, and `species`, have complete data for all characters, while others, such as `cybernetics`, `vehicles`, and `birth_place`, have many missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3583f-bac8-4b77-ab13-2eb9a34f0547",
   "metadata": {},
   "source": [
    "**Example 4.** Select and display the `mass` column from the `starwars` dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90792a5-680c-447a-a7c3-34388a141dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'mass' column from the starwars DataFrame\n",
    "# Returns a Series of character masses\n",
    "# The index on the left corresponds to the row number (i.e., each character)\n",
    "# NaN means that the mass value is missing for that character\n",
    "starwars[\"mass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb3f85-ce94-4a98-a238-8035450a77f8",
   "metadata": {},
   "source": [
    "**Output Observations:** The output shows the values in the `mass` column for each character in the dataset. Each entry represents a character's mass in kilograms. Some values may be missing (shown as `NaN`), which means data wasn't available for those characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e646c-5a85-4eed-8275-5e653b952d95",
   "metadata": {},
   "source": [
    "**Example 5.** Use the `.describe()` method to generate summary statistics for the `mass` column in the `starwars` dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942df34-2379-4fcb-bfbd-35b673cb8e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates summary statistics for the 'mass' column\n",
    "# count – number of non-missing values\n",
    "# mean – average mass\n",
    "# std – standard deviation (shows spread)\n",
    "# min – smallest mass\n",
    "# 25%, 50%, 75% – quartiles (values that split the data into four parts)\n",
    "# max – largest mass\n",
    "starwars[\"mass\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ff4a-50d6-4155-a45c-6a5f0dd579e0",
   "metadata": {},
   "source": [
    "**Output Observations:** There are 65 entries with non-missing values. The average (mean) mass is about 94.35 kg, but the very large maximum value (1358 kg) suggests it may be and outlier. Most character masses fall between 55 kg (25th percentile) and 84 kg (75th percentile), with the median (50th percentile) being 79 kg. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef11a4f-e46e-4e39-8869-154e2d99d6f1",
   "metadata": {},
   "source": [
    "**Example 6.** Create a histogram of the `mass` column to visualize the distribution of character masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d6f69-d204-4b27-b2a7-ca07ec9cd304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"mass\"] uses bracket notation to select a single column from the DataFrame\n",
    "# The result is a pandas Series containing just the 'mass' values\n",
    "# .hist() creates a histogram to show the frequency of different mass ranges\n",
    "starwars[\"mass\"].hist()\n",
    "\n",
    "# Turns off the background grid in the plot for a cleaner visual\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a0c8e-6ca2-4501-89d8-5cf502ce4602",
   "metadata": {},
   "source": [
    "**Output Observations:** Most characters have a mass between about 50 and 100 kg. A few characters have much higher masses, which appear as a bar far to the right, indicating possible outliers. The shape of the histogram appear right-skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3548efc-0c0c-4ddc-8055-db30dd53b42a",
   "metadata": {},
   "source": [
    "**Example 7.** Count how many times each species appears in the `species` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc47f1-d840-45c3-9340-aa6d375bc739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"species\"] uses bracket notation to select the 'species' column from the DataFrame\n",
    "# This returns a pandas Series containing all species values\n",
    "# .value_counts() counts how many times each unique value appears\n",
    "# The result is sorted by count, from most to least common\n",
    "starwars[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee0b64-84d7-4f14-a230-dbf954219b0a",
   "metadata": {},
   "source": [
    "**Output Observations:** Humans are the most common, with 38 characters, followed by Droids with 6. A few species appear multiple times (like Wookiees, Twi'leks, and Gungans), but most species appear only once. This indicates that while the dataset includes a wide variety of species, many are represented by just a single character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510ecbd-26cc-4131-ad59-f04af11fa700",
   "metadata": {},
   "source": [
    "**Example 8.** Create a horizontal bar chart to visualize the species counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb530d-97a7-4205-89a4-cf03e7c24120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starwars[\"species\"] uses bracket notation to select the 'species' column\n",
    "# .value_counts() counts how many times each species appears\n",
    "# The result is saved to a variable called tbl\n",
    "tbl = starwars[\"species\"].value_counts()\n",
    "\n",
    "# Creates a horizontal bar chart of the species counts\n",
    "# kind='barh' specifies a horizontal bar plot\n",
    "tbl.plot(kind = 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a262539-4605-419d-b48d-dabaebbfe165",
   "metadata": {},
   "source": [
    "**Output Observations:** The chart shows that Humans are by far the most common species in the dataset, followed by Droids. A few other species like Gungans, Mirialans, and Wookiees appear more than once, but most species are represented by just one character. However, the chart is difficult to read because it includes too many categories, with a total of 39 species, which makes the plot very tall and crowded. Many of the species names are long and placed close together, causing the labels to overlap or appear cramped. Additionally, the chart is visually unbalanced because most species appear only once, making their bars very short and hard to compare, while a few species dominate the plot with much longer bars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f2789-334b-400d-b748-03c08843930c",
   "metadata": {},
   "source": [
    "**Example 9.** Create a horizontal bar chart to visualize the species counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b719-f6dc-425b-a67c-19a4e930672f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count how many times each species appears\n",
    "tbl = starwars[\"species\"].value_counts()\n",
    "\n",
    "# Combine all species from index 2 onward (everything except the top 2) \n",
    "# into a new Series labeled \"Other\"\n",
    "other = pd.Series([tbl[2:].sum()], index=[\"Other\"])\n",
    "\n",
    "# Concatenate the top 2 species with the \"Other\" group\n",
    "# Then sort the result so the bars appear in order from \n",
    "# smallest to largest\n",
    "pd.concat([tbl.iloc[0:2], other]).sort_values(ascending=True).plot(kind = 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e12e28-3f1c-4b9d-8465-4f0a1632cf5a",
   "metadata": {},
   "source": [
    "**Output Observations:**  This chart simplifies the original crowded bar plot by showing only the two most frequent species, Humans and Droids, and combining all the others into a single \"Other\" category. This makes the chart easier to read and still communicates the key insight. Humans make up the largest portion of the dataset, followed by Droids, while the remaining species collectively form a much smaller group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a75412-7e06-4675-9e0c-2afc3f4943a8",
   "metadata": {},
   "source": [
    "**Example 10.** Count how many times each eye color appears in the `eye_color` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53404e7-1359-457e-862d-f631cfabbb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'eye_color' column using bracket notation\n",
    "# Returns a Series of eye colors for all characters\n",
    "# .value_counts() counts how many times each unique eye color appears\n",
    "# The result is sorted from most to least frequent\n",
    "starwars[\"eye_color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e2683-713e-4a81-9656-e44866e7374a",
   "metadata": {},
   "source": [
    "**Output Observations:**  The output shows that the most common eye colors among characters are blue (19), brown (18), and black (11). A few other colors like orange, yellow, and red also appear multiple times. However, most of the remaining eye colors occur only once or twice, such as green-gold, dark brown, and red, blue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a19052-d496-4e7d-aa27-529f02582af5",
   "metadata": {},
   "source": [
    "**Example 11.** Count how many times each hair color appears in the `hair_color` column of the `starwars` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06c5ea-1972-4eb0-a5bd-02eb91ab0468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'hair_color' column from the DataFrame using bracket notation\n",
    "# This returns a Series of all hair color values\n",
    "# .value_counts() counts how often each unique value appears\n",
    "# The result is sorted from most to least frequent\n",
    "starwars[\"hair_color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cf0e3-fd42-4ed2-bf97-6cbe5813b2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counts how many times each unique hair color appears\n",
    "# dropna=False includes missing values (NaN) in the count\n",
    "# Without this, missing values would be excluded by default\n",
    "starwars[\"hair_color\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2eb176-027e-49f4-9e5d-09ba34f95a28",
   "metadata": {},
   "source": [
    "**Output Observations:** This output shows that \"none\" is the most common value, appearing 36 times, followed by brown and black. The value `NaN` appears 5 times, indicating that some characters, like Droids, have missing hair color data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbef3f-58aa-4ac0-9391-354ddc835941",
   "metadata": {},
   "source": [
    "**Example 12.** Create a cross-tabulation table to compare eye color and hair color. Use `pd.crosstab()` to count how many characters have each combination of eye color and hair color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1a37f-853a-465b-b370-14d4a79f0f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a cross-tabulation of eye color (rows) and hair color (columns)\n",
    "# Counts how many characters fall into each combination of eye color and hair color\n",
    "# Stores the result in a new table called tbl\n",
    "tbl = pd.crosstab(starwars[\"eye_color\"], starwars[\"hair_color\"])\n",
    "\n",
    "# Display the resulting table\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c48a8-5ada-47a8-9d08-9dbc9d83801e",
   "metadata": {},
   "source": [
    "**Output Observations:** The most frequent combinations include brown eyes with black or brown hair, and blue eyes with brown, blond, or auburn hair. Some combinations, like black eyes with no hair or red eyes with no hair, also appear multiple times. Many cells in the table contain zeros, indicating that most combinations of eye and hair color do not occur. This suggests that while a few color combinations are common, the overall variety is limited, with only certain pairs appearing repeatedly in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4c1f7-3bc8-4bda-ad1c-229755a09721",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cc2c3-fea3-4c83-9ad1-7204f13352b4",
   "metadata": {},
   "source": [
    "**Example 13.** Filter the `starwars` dataframe to include only rows where the character's species is `\"Human\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f92f1-10c1-4919-a70d-c515ab7a11dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'species' column using bracket notation\n",
    "# Compares each value to the string \"Human\"\n",
    "# Returns a Series of True/False values, one for each row\n",
    "# True means the character is Human; False means they are not\n",
    "starwars[\"species\"] == \"Human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c75098-107f-4973-854d-5f8afbc298cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a Boolean Series (True/False) where True means the character is Human\n",
    "mask = starwars[\"species\"] == \"Human\"\n",
    "\n",
    "# Uses the mask to filter the DataFrame and keep only Human characters\n",
    "human = starwars[mask]\n",
    "\n",
    "# Displays the first 5 rows of the filtered DataFrame\n",
    "human.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475b3cd-25b7-4844-b03c-0dddcc82090b",
   "metadata": {},
   "source": [
    "**Example 14.** Use the `.describe()` method to generate summary statistics for the `mass` column in the `human` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ea601-e924-4cfe-954c-cdbe1d238d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .describe() method is used to generate summary statistics for numeric data\n",
    "# It returns values like count, mean, standard deviation, min, max, and quartiles\n",
    "# In this case, it's applied to the 'mass' column of the humans dataframe\n",
    "human[\"mass\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0379e-0209-4201-bf85-5ba964d13196",
   "metadata": {},
   "source": [
    "**Output Observations:** The summary statistics show that there are 26 Human characters with recorded mass values. The average mass is about 80.9 kg, and most values fall between 76.25 kg (25th percentile) and 84 kg (75th percentile), with a median of 79 kg. The lightest character weighs 45 kg, while the heaviest is 136 kg. The standard deviation of about 18.7 indicates moderate variation in mass among Human characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6eaeba-186a-4f67-8e48-36246f0090ce",
   "metadata": {},
   "source": [
    "**Example 14.** Create a histogram to visualize the distribution of mass for Human characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c33d97-7ea9-4a6f-a8b4-9e3da98a3f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for Human characters\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "human[\"mass\"].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dbd50-a620-4dfb-8748-fc2173dca68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for Human characters\n",
    "# bins=5 groups the data into 5 bars (bins) instead of the default number\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "human[\"mass\"].hist(bins=5, edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f758-a58e-408c-8d03-6f054f691ccb",
   "metadata": {},
   "source": [
    "**Output Observations:** This histogram shows the distribution of mass for Human characters, grouped into 5 bins. Most characters have a mass between approximately 65 and 85 kg, as indicated by the tallest bar. A few characters fall below 65 kg or above 100 kg, with very few in the highest mass range near 135 kg. The shape of the distribution is slightly right-skewed, meaning there are some heavier outliers that stretch the data to the right. This pattern aligns with the earlier summary statistics, where the mean was around 81 kg but the maximum reached 136 kg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201bd84-2b92-4d32-afc2-75377f6c0ff5",
   "metadata": {},
   "source": [
    "**Example 15.** Create a `DataFrame` that includes only characters who are not Human or Droid, and one that includes only characters who are Droids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daf0b3-9d80-4747-9d63-83d7684b48a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a new DataFrame with all characters who are NOT Human AND NOT Droid\n",
    "# The != operator means \"not equal to\"\n",
    "# The & operator is used to combine both conditions\n",
    "other = starwars[(starwars[\"species\"] != \"Human\") & (starwars[\"species\"] != \"Droid\")]\n",
    "\n",
    "# Creates a new DataFrame with only the characters whose species is Droid\n",
    "droid = starwars[starwars[\"species\"] == \"Droid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8969b91-f43c-42ce-b265-e305d5243e3b",
   "metadata": {},
   "source": [
    "**Example 16.** Create a histogram to visualize the distribution of mass for all characters who are not Human or Droid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4351df-c335-4ece-8316-b81c32bac233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for characters who are not Human or Droid\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "other[\"mass\"].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45aac7-6630-47f1-9eb2-6b80090a33ae",
   "metadata": {},
   "source": [
    "**Output Observations:** This histogram shows the distribution of mass for characters who are not Human or Droid. Most characters in this group have a mass under 200 kg, with the majority concentrated in the lowest range. However, there are a few extreme outliers with much higher mass values; one even above 1200 kg—which causes the chart to be right-skewed. These outliers stretch the x-axis and make the bulk of the data appear compressed on the left side of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185be2ce-767e-4a2c-915a-3e093cd97084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sorts the 'mass' values for characters who are not Human or Droid\n",
    "# Values are sorted from largest to smallest (descending order)\n",
    "other[\"mass\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf4b20-f71e-41dc-b054-2003a7e9fa7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sorts the 'mass' values for non-Human, non-Droid characters in descending order\n",
    "# [1:] removes the first (largest) value to reduce the effect of the outlier\n",
    "# Creates a histogram of the remaining mass values\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "other[\"mass\"].sort_values(ascending=False)[1:].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b61532-1191-45e0-92c5-404bd17b9848",
   "metadata": {},
   "source": [
    "**Output Observations:** This histogram shows the distribution of mass for non-Human, non-Droid characters after removing the largest outlier. Without the extreme value, most characters now have a mass between about 40 and 100 kg, with the highest concentration around 60 to 80 kg. A few characters still have higher masses (up to around 150 kg), but the overall shape is more balanced and could be viewed a slightly bi-modal or even right-skewed, even though most fall within a moderate range. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564726e6-5a72-412c-b4f8-b3138d7ce5c7",
   "metadata": {},
   "source": [
    "### Calculating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db20ca47-912f-4f0c-9041-30f3e3814be5",
   "metadata": {},
   "source": [
    "**Example 17.** Convert all the heights in the `starwars` dataframe from meters to centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb74315-373e-41b1-85d6-e64446cbdaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converts the 'height' column from centimeters to meters\n",
    "# Divides each value in the 'height' column by 100\n",
    "# This returns a Series of height in meters for each character\n",
    "starwars[\"height\"] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9908053-836e-45e3-88c9-3ba4a685ea4c",
   "metadata": {},
   "source": [
    "**Example 18.** Create a new column in the `starwars` `DataFrame` called `height_m` that stores each character's height in meters. Then, display all column names to confirm that the new column was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff8615-7183-43d2-b56f-f671b5c86297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a new column called 'height_m' by converting height from centimeters to meters\n",
    "starwars[\"height_m\"] = starwars[\"height\"] / 100\n",
    "\n",
    "# Displays the names of all columns to confirm the new column was added\n",
    "starwars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40fc7c-2d97-4044-8174-e3887fe03864",
   "metadata": {},
   "source": [
    "**Example 19.** Calculate the Body Mass Index (BMI) for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11d705-c793-4338-824f-7b9cb5d45066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates BMI using the formula: mass (kg) divided by height (m) squared\n",
    "# 'mass' in kilograms\n",
    "# 'height_m' in meters\n",
    "# This returns a Series of BMI values for each character\n",
    "starwars[\"mass\"] / (starwars[\"height_m\"]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5b088-8f44-4a15-8eda-b204f4b9238b",
   "metadata": {},
   "source": [
    "**Example 20.** Create a new column called `bmi` in the `starwars` `DataFrame` by calculating the Body Mass Index (BMI) for each character. Then display the column names to confirm the new column was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c9aa5-c690-4620-8cbc-44022d80f9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars[\"bmi\"] = starwars[\"mass\"] / (starwars[\"height_m\"]**2)\n",
    "starwars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5510b8fb-d585-4f2f-b4c9-544898952ed2",
   "metadata": {},
   "source": [
    "**Example 21.** Create a list that classifies each character as either `\"Human\"`, `\"Droid\"`, or `\"Other\"` based on the value in the `species` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26e557-c387-400a-b0f0-358c56d5a028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store the new species labels\n",
    "species = []\n",
    "\n",
    "# Loop through each value in the 'species' column\n",
    "for label in starwars[\"species\"]:\n",
    "    \n",
    "    # If the species is Human or Droid, keep the original label\n",
    "    if label in [\"Human\", \"Droid\"]:\n",
    "        species.append(label)\n",
    "    \n",
    "    # If the species is something else, label it as \"Other\"\n",
    "    else:\n",
    "        species.append(\"Other\")\n",
    "\n",
    "# Print the final list of species labels\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6291b8-baf8-4470-9b1a-c15bd4d34424",
   "metadata": {},
   "source": [
    "**Example 22.** Use the `.isin()` method to filter the the `starwars` `DataFrame` to identify which rows correspond to characters whose species is either Human or Droid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e62f50-4367-492c-bac4-6d6a84a58aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks if the value in the 'species' column is either \"Human\" or \"Droid\"\n",
    "# .isin() returns True if the species is in the list, otherwise False\n",
    "# This returns a Series of True/False values\n",
    "starwars[\"species\"].isin([\"Human\", \"Droid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59b1ad-d171-472d-9fde-2261f7e3f766",
   "metadata": {},
   "source": [
    "**Example 23.** Use `np.where` to create an array that classifies each character as either `\"Human\"`, `\"Droid\"`, or `\"Other\"` based on the value in the species column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b916f-a44a-4bd2-ad8d-0bd66ef96dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses np.where to classify species as \"Human\", \"Droid\", or \"Other\"\n",
    "# The first argument checks if each species is either \"Human\" or \"Droid\"\n",
    "# The second argument keeps the original species if the condition is True\n",
    "# The third argument replaces all other species with \"Other\"\n",
    "# This returns a numpy array with values\n",
    "np.where(starwars[\"species\"].isin([\"Human\", \"Droid\"]), starwars[\"species\"], \"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1a826-e5e7-4025-a000-85ea727b2911",
   "metadata": {},
   "source": [
    "`group_species` is a user-defined function that classifies a species value as either `\"Human\"`, `\"Droid\"`, or `\"Other\"`. It takes a single input, `s`, which must be a string of `None`. If the input is `\"Human\"` or `\"Droid\"`, the function returns that same value. If the input is anything other species name or missing values, it returns `\"Other\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc5a14-5ae8-4668-9d8b-124f2dd0be0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_species(s):\n",
    "    \"\"\"\n",
    "    Classifies a species value as 'Human', 'Droid', or 'Other'.\n",
    "    \n",
    "    Examples:\n",
    "    \n",
    "    group_species(\"Human\")  returns \"Human\"\n",
    "    group_species(\"Rodian\") returns \"Other\"\n",
    "    group_species(\"Droid\")  returns \"Droid\"\n",
    "\n",
    "    Parameters:\n",
    "    s: A single species value from the dataset.\n",
    "\n",
    "    Returns:\n",
    "    str: Returns 'Human' or 'Droid' if the input matches those values. \n",
    "         Otherwise returns 'Other'.\n",
    "         \n",
    "    Precondition: s is a string or None\n",
    "    \"\"\"\n",
    "    if s in [\"Human\", \"Droid\"]:\n",
    "        return s\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0be79-1b98-4ec4-b6d0-3e046acd03e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .apply() runs the group_species function on each value in the 'species' column\n",
    "# It goes through the column one row at a time\n",
    "# This returns a Series of values of 'Human', 'Droid', or 'Other'\n",
    "starwars[\"species\"].apply(group_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a74ab-636f-463d-9655-7eb4fa427a74",
   "metadata": {},
   "source": [
    "You can use any of the previously demonstrated programming techniques to add a column to the `starwars` `DataFrame`. \n",
    "\n",
    "```python\n",
    "starwars[\"species_grps\"] = species\n",
    "starwars[\"species_grps\"] = starwars[\"species\"].apply(group_species)\n",
    "starwars[\"species_grps\"] = np.where(starwars[\"species\"].isin([\"Human\", \"Droid\"]), starwars[\"species\"], \"Other\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a3578-859c-47eb-a384-3eb8ded08204",
   "metadata": {},
   "source": [
    "**Example 24.** Choose a technique to add a new column to the `starwars` `DataFrame` that classifies each character as `\"Human\"`, `\"Droid\"`, or `\"Other\"` based on their species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdeed9-78a7-4440-a8ee-ad6ac353f2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars[\"species_grps\"] = ...\n",
    "starwars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc88d26-5b6d-46e5-a296-f8ce1c288d67",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b3126-a7f3-47aa-bbcb-1676451bfe3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .groupby() method is used to group the DataFrame by the \n",
    "# values in 'species_grps' column\n",
    "# It creates a GroupBy object that allows you to perform \n",
    "# operations separately for each group\n",
    "starwars.groupby(\"species_grps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33642eeb-55e8-4342-8949-6c52fa0d983f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses the .groupby() method to group the DataFrame by the 'species_grps' column\n",
    "# Stores the resulting GroupBy object in the variable 'grps'\n",
    "grps = starwars.groupby(\"species_grps\")\n",
    "\n",
    "# Accesses the dictionary of group labels (keys) from the GroupBy object\n",
    "# This returns a view object with the unique values \n",
    "# in 'species_grps' that were used to form the groups\n",
    "grps.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586578fc-aa08-4385-bf86-cc4c1d1f5043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accesses the .groups attribute of the GroupBy object\n",
    "# This returns a dictionary where the keys are group labels (e.g., 'Human', 'Droid', 'Other')\n",
    "# and the values are lists of row indices from the DataFrame that belong to each group\n",
    "grps.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d731e7-d77b-47bb-b87b-037576bcb94d",
   "metadata": {},
   "source": [
    "**Example 25.** Use the `grps` `GroupBy` object to calculate the average mass for each species group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55064a1-09b2-445c-ba8f-dc45e371f576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'mass' column from the GroupBy object 'grps'\n",
    "# Uses the .mean() method to calculate the average mass for each group in 'species_grps'\n",
    "# Returns a Series showing the mean mass for Humans, Droids, and Other species\n",
    "grps[\"mass\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0125e1-3aa9-45e3-8a1f-c2a81627d459",
   "metadata": {},
   "source": [
    "**Output Observations:** \n",
    "\n",
    "- Droids have the lowest average mass at about 59.4 kg, which may reflect compact mechanical designs or smaller body types.\n",
    "\n",
    "- Humans have an average mass of 80.9 kg, which is typical for an adult and falls within a normal range depending on height.\n",
    "\n",
    "- Other species have the highest average mass at 109.8 kg, suggesting that many non-human characters in the Star Wars universe are larger-bodied or denser than humans or droids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968bf63-da95-4bd2-befc-b2303427dc28",
   "metadata": {},
   "source": [
    "**Example 26.** Use the `grps` `GroupBy` object to count how many times each homeworld appears within each species group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95693627-71f2-4311-b833-a01eeb08333c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'homeworld' column from the GroupBy object 'grps'\n",
    "# Applies .value_counts() to count how many times each homeworld appears within each species group\n",
    "# Returns a Series with counts of homeworlds for 'Human', 'Droid', and 'Other' groups\n",
    "grps[\"homeworld\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada248d-0682-41e0-aacf-e8d183020a4e",
   "metadata": {},
   "source": [
    "**Example 27.** Create a box plot to compare the distribution of character heights across the three species groups: `\"Human\"`, `\"Droid\"`, and `\"Other\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a7936-80f1-4bbd-ba0e-911010c59562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a box plot of the 'height' column grouped by 'species_grps'\n",
    "# This shows the median, quartiles, and possible outliers for each group\n",
    "starwars.boxplot(column=\"height\", by=\"species_grps\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b80612-2f82-4633-9d37-03f20d166561",
   "metadata": {},
   "source": [
    "**Output Observations:** \n",
    "\n",
    "- Droids have the widest range of heights, with values spread from around 70 cm to 200 cm. Their heights are more varied, and the box is larger, indicating more variability in the middle 50% of values.\n",
    "\n",
    "- Humans have the most consistent height distribution. Their heights are tightly clustered around the median of approximately 180 cm, with very few outliers and a narrow interquartile range.\n",
    "\n",
    "- Other species show a higher median height than Droids and Humans and also have the largest number of outliers, both on the short and tall ends. This group has a broader spread and more variability overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18028f5-f89a-49bd-8db2-1617ab7791f7",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1e3eb-c65b-47fa-934f-1a2ebb9630c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Popular Baby Names Dataset\n",
    "\n",
    "This dataset contains state-specific data on the relative frequency of given names for individuals issued a Social Security Number in the United States. Data is tabulated from Social Security Administration records as of March 2, 2025. The files include annual birth name frequencies by sex and state, beginning in 1910, for all 50 states and the District of Columbia.\n",
    "\n",
    "Each file lists names with at least 5 occurrences in a given year to protect individual privacy. Records are sorted by sex, year, and descending frequency, with alphabetical order breaking ties, which enables direct rank determination.\n",
    "\n",
    "#### Popular Baby Names Datasheet\n",
    "\n",
    "[Popular Baby Names Datasheet](https://docs.google.com/document/d/1uMFpRbvO1NhGVvfRSw3eDpp1O-6a7UeLE3GeZ8OfTuM/edit?usp=sharing)\n",
    "\n",
    "Social Security Administration. (n.d.). Popular baby names: Data limits and exclusions. Retrieved March 2, 2025, from https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "The code below loads a subset of state files into separate dataframes. The table that follows shows how each file corresponds to its respective dataframe.\n",
    "\n",
    "|State|Abbreviation|\n",
    "|:-----|:------------|\n",
    "|Indiana| `ind`|\n",
    "|Michigan| `mich`|\n",
    "|Ohio| `ohio`| \n",
    "|Pennsylvania| `penn`|\n",
    "|North Carolina| `nc`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c99ca6-9cd9-4c62-94ce-15fa7cbfb782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind = pd.read_csv(\"data/IN.TXT\")\n",
    "mich = pd.read_csv(\"data/MI.TXT\")\n",
    "ohio = pd.read_csv(\"data/OH.TXT\")\n",
    "penn = pd.read_csv(\"data/PA.TXT\")\n",
    "nc = pd.read_csv(\"data/NC.TXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c794ce0-876b-404e-99d0-7d4c171599c3",
   "metadata": {},
   "source": [
    "It’s good practice to inspect the structure and metadata of a `DataFrame` using the `.info()` method.\n",
    "\n",
    "**Structure** refers to the overall layout of the `DataFrame`, including:\n",
    "- Number of rows and columns\n",
    "- Column names\n",
    "- Data types (e.g., int64, object, float64)\n",
    "- Index type and range\n",
    "\n",
    "**Metadata** refers to information about the data rather than the data itself, including:\n",
    "- Which columns contain missing values (non-null counts)\n",
    "- Total memory usage\n",
    "- Index type\n",
    "\n",
    "**Example 27.** Run the cell below. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc766d-fcfc-4374-925b-97e28e544171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968937d2-0747-4446-a857-1204b283c56f",
   "metadata": {},
   "source": [
    "**Output Observations:** \n",
    "\n",
    "- No missing values: All five columns have 213,756 non-null entries, which means the dataset has no missing values.\n",
    "\n",
    "- Column names look like data, not labels: The column names are values like \"OH\", \"F\", \"1910\", \"Mary\", and \"1099\"—these are likely meant to be the first row of data, not actual column headers. These suggest the header row was not correctly read, and the first row of actual data became the column names.\n",
    "\n",
    "Let's look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80d81-3918-4b9a-80dd-91d91ae26500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d3ab5-fc78-4867-9dcf-ae34b0b63502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reads the 'OH.TXT' file from the 'data' folder into a DataFrame named 'ohio'\n",
    "# header=None tells pandas that the file does not have a header row, so it should \n",
    "# not treat the first row as column names\n",
    "# Default column names will be assigned as integers: 0, 1, 2, 3, etc.\n",
    "ohio = pd.read_csv(\"data/OH.TXT\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ea617-81c2-49a3-b816-da2ce810fd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5b5fa-243f-4018-9643-904b642a561a",
   "metadata": {},
   "source": [
    "**Example 28.** Rename the columns of the `ohio` `DataFrame` as `state`, `sex`, `year`, `name`, and `count`. Then, display all column names to confirm that the new column was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f0355-835d-4c5a-9122-f2e8e23df35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assigns custom column names to the 'ohio' DataFrame\n",
    "# These names replace the default numeric column \n",
    "# labels (0, 1, 2, 3, 4)\n",
    "ohio.columns = ['state', 'sex', 'year', 'name', 'count']\n",
    "ohio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8250fec-d636-45f1-b57c-cfce42b111fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d947c-7459-4398-b06f-35ca3bbc10a4",
   "metadata": {},
   "source": [
    "**Example 29.** Filter the `ohio` `DataFrame` for the name \"Alexa\" to see how its popularity has changed overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d499ec-4591-4e5f-8e54-f421a9bd53b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = \"Alexa\"\n",
    "\n",
    "# Creates a Boolean mask that is True for rows where the 'name' column matches the variable 'name'\n",
    "mask = ohio[\"name\"] == name\n",
    "\n",
    "# Uses the mask to filter the DataFrame and return only the matching rows\n",
    "# Then selects the 'year' and 'count' columns using double brackets [[...]] to return a DataFrame\n",
    "ohio[mask][[\"year\", \"count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27ea4a-6c7b-4a25-99d4-3842fed8f014",
   "metadata": {},
   "source": [
    "**Example 30.** Create a line chart to visualize how the popularity of the name \"Alexa\" has changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a3b1f-906c-4e2e-a835-9752f15b9650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohio[ohio[\"name\"] == name].plot(x=\"year\", y=\"count\", kind=\"line\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8038a48-7bd6-497f-b00c-8dc763a4f4b8",
   "metadata": {},
   "source": [
    "**Output Observations:** This line chart shows the number of babies named Alexa each year. From the 1950s through the early 1980s, the name was used very rarely. Starting around the mid-1980s, its popularity began to rise sharply, peaking between 1995 and 2010, with counts exceeding 150 per year. After that, there is a dramatic decline, especially after 2015, where the number of babies named Alexa drops rapidly. This suggests that the name experienced a strong surge in popularity followed by a steep decline. This was most likely influenced by cultural or technological factors (such as the release of Amazon’s Alexa in 2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f4c5e-a736-401b-9a2f-344b39f09e94",
   "metadata": {},
   "source": [
    "**Example 31.** Merge the Michigan data with the Ohio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320922c5-f0f5-40db-a6e1-4ddc50b1c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mich = pd.read_csv(\"data/MI.TXT\", header=None)\n",
    "mich.columns = ['state', 'sex', 'year', 'name', 'count']\n",
    "mich.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb40cf-71ba-4786-acc7-b4a134b0905c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combines the 'ohio' and 'mich' DataFrames into a single DataFrame using pd.concat()\n",
    "# ignore_index=True resets the row index so it runs from 0 to n-1 in the combined DataFrame\n",
    "pd.concat([ohio, mich], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d919c-83ea-4e04-849b-74b36bcc8cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stores the combined data from both Ohio and Michigan in a DataFrame\n",
    "ohio_mich = pd.concat([ohio, mich], ignore_index=True)\n",
    "\n",
    "# Displays the combined DataFrame with data from both Ohio and Michigan\n",
    "# By default the first 5 and the last 5 rows are shown\n",
    "ohio_mich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fb99f-f3ed-4456-8e8c-f934fd9648da",
   "metadata": {},
   "source": [
    "### Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b53a48-7c68-467e-ac6a-276ee6ddfd4c",
   "metadata": {},
   "source": [
    "### CEO Compensation Summary Dataset\n",
    "\n",
    "The data from the AFL-CIO Executive Paywatch database draws from company proxy statements that are filed with the U.S. Securities and Exchange Commission and collected by [pay-gap.com](https://aflcio.org/paywatch/pay-gap.com). The database includes data for some 3,000 corporations, including most of those listed in the Russell 3000 Index. Industry classifications are based on North American Industry Classification System codes.\n",
    "\n",
    "#### CEO Compensation Summary Datasheet\n",
    "\n",
    "[CEO Compensation Summary Datasheet](https://docs.google.com/document/d/1AJriZiqMarx8-r4WZwoXoCkFKLEDpq2jt0V6t5_tQLM/edit?usp=drive_link)\n",
    "\n",
    "AFL-CIO. (n.d.). Highest-Paid CEOs. Retrieved 2022, from https://aflcio.org/paywatch/highest-paid-ceos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd758267-b93f-481a-883f-d563786dd508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ceo = pd.read_csv(\"data/ceo_compensation_summary.csv\")\n",
    "ceo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53f00f-c8e8-4071-bf83-4ac12cbb06b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ceo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba622c1-b668-4312-8c11-ed48d42c4267",
   "metadata": {},
   "source": [
    "### Compnay Information Dataset\n",
    "\n",
    "The companies in this dataset come from the AFL-CIO Executive Paywatch database, which compiles data from company proxy statements filed with the U.S. Securities and Exchange Commission and collected by paygap.com. The dataset includes approximately 3,000 corporations, primarily those listed in the Russell 3000 Index, with industry classifications based on North American Industry Classification System (NAICS) codes. To supplement this dataset, additional company information including sector, industry, and market capitalization was collected using the Python yfinance library, which provides streamlined access to company data from Yahoo Finance.\n",
    "\n",
    "#### Compnay Information Datasheet\n",
    "\n",
    "[Compnay Information Datasheet](https://docs.google.com/document/d/1t_J1RKSpc8qXhozS8F1K82Ac-429zETQUJXT8PvRCm0/edit?usp=sharing)\n",
    "\n",
    "Ran, A. (2019). yfinance: Yahoo! Finance market data downloader [Python library]. https://github.com/ranaroussi/yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc31649-ba8d-407d-9a5b-30b326053f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv(\"data/company_information.csv\")\n",
    "company.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a36f1e-a6cf-4b97-a50c-4bd72b366d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4e8f0-040a-42ad-abb5-3b5e8da5ae14",
   "metadata": {},
   "source": [
    "**Example 32.** Display the column names from the both the `ceo` and the `company` `DtatFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb0439-b203-4c13-9319-176d3d974c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Colimns in the ceo dataframe\")\n",
    "print(ceo.columns)\n",
    "print(\"\\n\")\n",
    "print(\"Columns in the company dataframe\")\n",
    "print(company.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c63293-a462-4a46-8176-3b0bddfd4207",
   "metadata": {},
   "source": [
    "**Example 33.** Display the information in the first row of the `ceo` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f8a48-7794-4e29-b578-b4ba01a6814e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .loc is a label-based accessor used to retrieve rows (and optionally columns) by index label\n",
    "# This line retrieves the row in the 'ceo' DataFrame with index label 0\n",
    "# It returns all column values for that row as a Series\n",
    "ceo.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82525158-e49f-4f05-b241-3eb6ab7e5440",
   "metadata": {},
   "source": [
    "**Example 34.** Display the information in the first row of the `company` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ee5a0-7645-41bd-bef3-fc965a4d43d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .loc is a label-based accessor used to retrieve rows (and optionally columns) by index label\n",
    "# This line retrieves the row in the 'company' DataFrame with index label 0\n",
    "# It returns all column values for that row as a Series\n",
    "company.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b9843-b80c-49e4-8a7e-1d1c231b41f2",
   "metadata": {},
   "source": [
    "**Example 35.** Use `pd.merge()` to combine the `ceo` and `company` dataframes based on the shared `ticker` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ebe57-c83d-4058-9ae4-1a3bac85f112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merges the 'ceo' and 'company' DataFrames using the 'ticker' column as the key\n",
    "# Only rows with matching 'ticker' values in both DataFrames will be included (inner join by default)\n",
    "# Returns a new DataFrame that combines columns from both sources\n",
    "pd.merge(ceo, company, on=\"ticker\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
