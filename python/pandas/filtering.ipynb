{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3029e100-8294-4f00-95df-09eb2c1df926",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is one part of the Data Investigation Process that can include data cleaning, wrangling, and visualization. The \"Data Moves\" framework:\n",
    "\n",
    "- Provides a structured set of categories (i.e., data moves) to describe and analyze how students engage with data\n",
    "\n",
    "- Supports instructional design and assessment by offering a lens through which educators can identify, understand, and demonstrate data practices\n",
    "\n",
    "Before exploring data, it is important to select datasets that are appropriate for students based on grade-level, subject area relevance, size, and number of freatures (i.e., variables). This notebook covers basic considerations that should be made before selecting datasets suitable for use in exploratory data analysis within an introductory data science course. It also provides examples of the core data moves along with explanations of output generated by each the move (e.g, a value, table, visualization, etc.).\n",
    "\n",
    "## Selecting a Dataset\n",
    "\n",
    "### Tidy Data\n",
    "\n",
    "The 2014 paper *Tidy Data* presents a structured framework for organizing datasets to support efficient analysis. In a tidy dataset, each variable forms a column, each observation forms a row, and each type of observational unit is stored in a separate table. It also outlines strategies for transforming messy data into tidy form, demonstrating how this approach simplifies and strengthens data analysis practices.\n",
    "\n",
    "Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10\n",
    "\n",
    "### Tame Data\n",
    "\n",
    "The 2018 paper The fivethirtyeight R Package introduces the concept of tame data, which refers to datasets that are clean, well-labeled, and easy to use in teaching. Tame data minimizes the need for wrangling so students can focus on analysis. The paper highlights the importance of using structured and accessible data in introductory statistics and data science courses.\n",
    "\n",
    "Kim, A. Y., Ismay, C., & Chunn, J. (2018). The fivethirtyeight R Package: “Tame Data” Principles for Introductory Statistics and Data Science Courses. Technology Innovations in Statistics Education, 11(1). https://doi.org/10.5070/T5111035892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de5ad7-ef7e-4cd1-abc2-5b1745f3fb70",
   "metadata": {},
   "source": [
    "## Investigating Data Like a Data Scientist\n",
    "\n",
    "Investigating data like a data scientist involves an iterative process of making sense of information. This process includes six key phases: \n",
    "\n",
    "- Framing the problem\n",
    "- Exploring and visualizing data\n",
    "- Modeling\n",
    "- Evaluating results\n",
    "- Crafting a narrative\n",
    "- Communicating findings\n",
    "\n",
    "These phases reflect authentic data science practice and provide a structure that support more meaningful engagement with data in educational settings.\n",
    "\n",
    "Rather than following a fixed procedure, this framework emphasizes the importance of habits of mind such as critical thinking, refining questions, and considering the audience. It highlights that data science relies not only on technical skills but also on decision-making, interpretation, and storytelling. When students are guided through these phases, they develop the analytical reasoning needed to navigate data and communicate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f700d5-9b19-402f-a43b-518b9eac5bce",
   "metadata": {},
   "source": [
    "## Data Investigation Process Framework\n",
    "\n",
    "\n",
    "### Frame Problem\n",
    "\n",
    "- Consider real-world phenomena and broader issues related to the problem\n",
    "- Pose investigative question(s)\n",
    "- Anticipate potential data and strategies\n",
    "\n",
    "### Consider & Gather Data\n",
    "\n",
    "- Understand possible attributes, measurements, and data collection methods needed for the problem\n",
    "- Evaluate and use appropriate design and techniques to collect or source data\n",
    "- Consider sample size, access, storage, and trustworthiness of data\n",
    "\n",
    "### Process Data\n",
    "\n",
    "- Organize, structure, clean, and transform data in efficient and useful ways\n",
    "- Consider additional data cases or attributes\n",
    "\n",
    "### Explore & Visualize Data\n",
    "\n",
    "- Construct meaningful visualizations, static or dynamic\n",
    "- Compute meaningful statistical measures\n",
    "- Explore and analyze data for potential relationships or patterns that address the problem\n",
    "\n",
    "### Consider Models\n",
    "\n",
    "- Analyze and identify models that address the problem\n",
    "- Consider assumptions and context of the models\n",
    "- Recognize possible limitations\n",
    "\n",
    "### Communicate & Propose Action\n",
    "\n",
    "- Craft a data story to convey insight to stakeholder audiences\n",
    "- Justify claims with evidence from data and propose possible action\n",
    "- Address uncertainty, constraints, and potential bias in the analysis\n",
    "\n",
    "Lee, H. S., Wilkerson, M. H., & Zuckerman, S. J. (2022). Investigating data like a data scientist: A framework for elementary, middle, and high school teachers. *Statistics Education Research Journal, 21*(2). [https://doi.org/10.52041/serj.v21i2.41](https://doi.org/10.52041/serj.v21i2.41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f8e39-2cac-4cbe-a3de-a1bab5569fe1",
   "metadata": {},
   "source": [
    "# Data Moves\n",
    "\n",
    "Data moves are strategic actions taken during data analysis to reshape and prepare datasets for interpretation. These include filtering, grouping, summarizing, calculating, merging or joining data, and creating hierarchical structures. Each move alters the structure, content, or values of a dataset, influencing what patterns become visible and what questions can be explored. By understanding these moves, learners gain insight into how data analysis is an active, decision-driven process rather than a passive application of procedures.\n",
    "\n",
    "Erickson, T., Tinker, R., & Yasuda, M. (2019). *Data moves*. UC Berkeley: The Concord Consortium. eScholarship, University of California. https://escholarship.org/uc/item/0mg8m7g6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc99e7a-e0e5-4db8-8ab4-d3914da8cac6",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Filtering produces a subset of data and serves at least two important purposes.\n",
    "\n",
    "- If a dataset includes extraneous cases, filtering removes the irrelevant ones. This is sometimes called scoping.\n",
    "- Filtering may be used in order to reduce the complexity or quantity of data in order to gain insight. Sometimes this is called slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753976c-790e-4597-85a4-7ed22449e3e3",
   "metadata": {},
   "source": [
    "# Data Dive\n",
    "\n",
    "A data dive is a focused exploratory analysis where students work closely with a dataset to uncover patterns, trends, and relationships by applying key data moves. For example, using a dataset about school lunch nutrition, students might begin by filtering to isolate meals served in a specific year or location. They could group the data by food category such as fruits, grains, or proteins to explore how nutritional content differs across types. Through summarizing, they might calculate the average number of calories or the typical sodium content for each group. Calculating might involve creating new variables, such as calories per gram or the percentage of a recommended daily intake. If additional data sources are provided, students could join datasets, such as connecting lunch menus with student demographic information, to add context and depth to their findings. These data moves help students make sense of multivariable datasets and support evidence-based insights.\n",
    "\n",
    "## Analysis with Data Moves in Python\n",
    "\n",
    "In this section, we present example use cases that demonstrate data moves using the Python programming language. While Python includes built-in tools and data structures for general data handling, it does not include a built-in data structure specifically designed for working with tidy data as defined by the _Tidy Data_ paper. To support the tidy data format and organize the analysis around data moves such as filtering, grouping, and summarizing, we will use the Pandas library for data wrangling, Numpy for scientific computing, and the Matplotlib library for creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba0a40-3b44-4635-9616-fbf8adfca33a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49403-b64c-445b-8e65-26afa6ef46bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8741ee1-ddbd-4df1-bb29-f2bbd529e22a",
   "metadata": {},
   "source": [
    "### Updated Starwars Dataset\n",
    "\n",
    "Fabricio Narcizo’s blog post, Introduction to Data Analysis using the Star Wars Dataset, presents an expanded version of the original R dplyr Star Wars dataset, growing it from 14 to 25 variables. By cross-referencing Wookieepedia, he corrected and enriched the character data with new fields like birth/death details, pronouns, occupations, and abilities, resulting in a more accurate and comprehensive dataset for analysis.\n",
    "\n",
    "#### Updated Starwars Datasheet\n",
    "\n",
    "[Updated Starwars Datasheet](https://docs.google.com/document/d/1Gr6W0xo1pxW-TZH2GKawIASqZ7JfURmzQO1Eg2JGsC8/edit?usp=sharing)\n",
    "\n",
    "Narcizo, F. B. (2023, December 30). Introduction to Data Analysis using the Star Wars Dataset. Retrieved from https://www.fabricionarcizo.com/post/starwars/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3076ce3-0bb2-4b49-a50d-6552bd38faf9",
   "metadata": {},
   "source": [
    "**Example 1.** Load the dataset into a pandas `DataFrame` called `starwars`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34680e91-0c05-4f70-a02e-68e20c916ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starwars = pd.read_csv(\"data/updated_starwars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4c1f7-3bc8-4bda-ad1c-229755a09721",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cc2c3-fea3-4c83-9ad1-7204f13352b4",
   "metadata": {},
   "source": [
    "**Example 2.** Filter the `starwars` dataframe to include only rows where the character's species is `\"Human\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f92f1-10c1-4919-a70d-c515ab7a11dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects the 'species' column using bracket notation\n",
    "# Compares each value to the string \"Human\"\n",
    "# Returns a Series of True/False values, one for each row\n",
    "# True means the character is Human; False means they are not\n",
    "starwars[\"species\"] == \"Human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c75098-107f-4973-854d-5f8afbc298cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a Boolean Series (True/False) where True means the character is Human\n",
    "mask = starwars[\"species\"] == \"Human\"\n",
    "\n",
    "# Uses the mask to filter the DataFrame and keep only Human characters\n",
    "human = starwars[mask]\n",
    "\n",
    "# Displays the first 5 rows of the filtered DataFrame\n",
    "human.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475b3cd-25b7-4844-b03c-0dddcc82090b",
   "metadata": {},
   "source": [
    "**Example 3.** Use the `.describe()` method to generate summary statistics for the `mass` column in the `human` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ea601-e924-4cfe-954c-cdbe1d238d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .describe() method is used to generate summary statistics for numeric data\n",
    "# It returns values like count, mean, standard deviation, min, max, and quartiles\n",
    "# In this case, it's applied to the 'mass' column of the humans dataframe\n",
    "human[\"mass\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0379e-0209-4201-bf85-5ba964d13196",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6eaeba-186a-4f67-8e48-36246f0090ce",
   "metadata": {},
   "source": [
    "**Example 4.** Create a histogram to visualize the distribution of mass for Human characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c33d97-7ea9-4a6f-a8b4-9e3da98a3f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for Human characters\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "human[\"mass\"].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dbd50-a620-4dfb-8748-fc2173dca68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for Human characters\n",
    "# bins=5 groups the data into 5 bars (bins) instead of the default number\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "human[\"mass\"].hist(bins=5, edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f758-a58e-408c-8d03-6f054f691ccb",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201bd84-2b92-4d32-afc2-75377f6c0ff5",
   "metadata": {},
   "source": [
    "**Example 5.** Create a `DataFrame` that includes only characters who are not Human or Droid, and one that includes only characters who are Droids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daf0b3-9d80-4747-9d63-83d7684b48a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a new DataFrame with all characters who are NOT Human AND NOT Droid\n",
    "# The != operator means \"not equal to\"\n",
    "# The & operator is used to combine both conditions\n",
    "other = starwars[(starwars[\"species\"] != \"Human\") & (starwars[\"species\"] != \"Droid\")]\n",
    "\n",
    "# Creates a new DataFrame with only the characters whose species is Droid\n",
    "droid = starwars[starwars[\"species\"] == \"Droid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8969b91-f43c-42ce-b265-e305d5243e3b",
   "metadata": {},
   "source": [
    "**Example 6.** Create a histogram to visualize the distribution of mass for all characters who are not Human or Droid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4351df-c335-4ece-8316-b81c32bac233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a histogram of the 'mass' column for characters who are not Human or Droid\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "other[\"mass\"].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45aac7-6630-47f1-9eb2-6b80090a33ae",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185be2ce-767e-4a2c-915a-3e093cd97084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sorts the 'mass' values for characters who are not Human or Droid\n",
    "# Values are sorted from largest to smallest (descending order)\n",
    "other[\"mass\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf4b20-f71e-41dc-b054-2003a7e9fa7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sorts the 'mass' values for non-Human, non-Droid characters in descending order\n",
    "# [1:] removes the first (largest) value to reduce the effect of the outlier\n",
    "# Creates a histogram of the remaining mass values\n",
    "# edgecolor=\"white\" adds a white border around each bar\n",
    "other[\"mass\"].sort_values(ascending=False)[1:].hist(edgecolor=\"white\")\n",
    "\n",
    "# Turns off the background grid\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b61532-1191-45e0-92c5-404bd17b9848",
   "metadata": {},
   "source": [
    "**Output Observations:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
